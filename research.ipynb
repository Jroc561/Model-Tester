{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "df = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target and features\n",
    "target = ''\n",
    "\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]\n",
    "\n",
    "# split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.25 ,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that compares the CV perfromance of a set of predetrmined models \n",
    "def cv_comparison(models, X, y, cv):\n",
    "    # Initiate a DataFrame for the averages and a list for all measures\n",
    "    cv_accuracies = pd.DataFrame()\n",
    "    maes = []\n",
    "    mses = []\n",
    "    r2s = []\n",
    "    accs = []\n",
    "    # Loop through the models, run a CV, add the average scores to the DataFrame and the scores of \n",
    "    # all CVs to the list\n",
    "    for model in models:\n",
    "        mae = -np.round(cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv), 4)\n",
    "        maes.append(mae)\n",
    "        mae_avg = round(mae.mean(), 4)\n",
    "        mse = -np.round(cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv), 4)\n",
    "        mses.append(mse)\n",
    "        mse_avg = round(mse.mean(), 4)\n",
    "        r2 = np.round(cross_val_score(model, X, y, scoring='r2', cv=cv), 4)\n",
    "        r2s.append(r2)\n",
    "        r2_avg = round(r2.mean(), 4)\n",
    "        acc = np.round((100 - (100 * (mae * len(X))) / sum(y)), 4)\n",
    "        accs.append(acc)\n",
    "        acc_avg = round(acc.mean(), 4)\n",
    "        cv_accuracies[str(model)] = [mae_avg, mse_avg, r2_avg, acc_avg]\n",
    "    cv_accuracies.index = ['Mean Absolute Error', 'Mean Squared Error', 'R^2', 'Accuracy']\n",
    "    return cv_accuracies, maes, mses, r2s, accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the models to be tested\n",
    "mlr_reg = LinearRegression()\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "xgb_reg = xgb_regressor = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Put the models in a list to be used for Cross-Validation\n",
    "models = [mlr_reg, rf_reg, xgb_reg]\n",
    "\n",
    "# Run the Cross-Validation comparison with the models used in this analysis\n",
    "comp, maes, mses, r2s, accs = cv_comparison(models, X_train, y_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for all R^2s\n",
    "r2_comp = pd.DataFrame(r2s, index=comp.columns, columns=['1st Fold', '2nd Fold', '3rd Fold', \n",
    "                                                         '4th Fold'])\n",
    "\n",
    "# Add a column for the averages\n",
    "r2_comp['Average'] = np.round(r2_comp.mean(axis=1),4)\n",
    "r2_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in Random Forest\n",
    "rf_n_estimators = [int(x) for x in np.linspace(200, 1000, 5)]\n",
    "rf_n_estimators.append(1500)\n",
    "rf_n_estimators.append(2000)\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "rf_max_depth = [int(x) for x in np.linspace(5, 55, 11)]\n",
    "# Add the default as a possible value\n",
    "rf_max_depth.append(None)\n",
    "\n",
    "# Number of features to consider at every split\n",
    "rf_max_features = ['auto', 'sqrt', 'log2']\n",
    "\n",
    "# Criterion to split on\n",
    "rf_criterion = ['mse', 'mae']\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "rf_min_samples_split = [int(x) for x in np.linspace(2, 10, 9)]\n",
    "\n",
    "# Minimum decrease in impurity required for split to happen\n",
    "rf_min_impurity_decrease = [0.0, 0.05, 0.1]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "rf_bootstrap = [True, False]\n",
    "\n",
    "# Create the grid\n",
    "rf_grid = {'n_estimators': rf_n_estimators,\n",
    "               'max_depth': rf_max_depth,\n",
    "               'max_features': rf_max_features,\n",
    "               'criterion': rf_criterion,\n",
    "               'min_samples_split': rf_min_samples_split,\n",
    "               'min_impurity_decrease': rf_min_impurity_decrease,\n",
    "               'bootstrap': rf_bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model to be tuned\n",
    "rf_base = RandomForestRegressor()\n",
    "\n",
    "# Create the random search Random Forest\n",
    "rf_random = RandomizedSearchCV(estimator = rf_base, param_distributions = rf_grid, \n",
    "                               n_iter = 200, cv = 3, verbose = 2, random_state = 42, \n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# View the best parameters from the random search\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees to be used\n",
    "xgb_n_estimators = [int(x) for x in np.linspace(200, 2000, 10)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "xgb_max_depth = [int(x) for x in np.linspace(2, 20, 10)]\n",
    "\n",
    "# Minimum number of instaces needed in each node\n",
    "xgb_min_child_weight = [int(x) for x in np.linspace(1, 10, 10)]\n",
    "\n",
    "# Tree construction algorithm used in XGBoost\n",
    "xgb_tree_method = ['auto', 'exact', 'approx', 'hist', 'gpu_hist']\n",
    "\n",
    "# Learning rate\n",
    "xgb_eta = [x for x in np.linspace(0.1, 0.6, 6)]\n",
    "\n",
    "# Minimum loss reduction required to make further partition\n",
    "xgb_gamma = [int(x) for x in np.linspace(0, 0.5, 6)]\n",
    "\n",
    "# Learning objective used\n",
    "xgb_objective = ['reg:squarederror', 'reg:squaredlogerror']\n",
    "\n",
    "# Create the grid\n",
    "xgb_grid = {'n_estimators': xgb_n_estimators,\n",
    "            'max_depth': xgb_max_depth,\n",
    "            'min_child_weight': xgb_min_child_weight,\n",
    "            'tree_method': xgb_tree_method,\n",
    "            'eta': xgb_eta,\n",
    "            'gamma': xgb_gamma,\n",
    "            'objective': xgb_objective}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model to be tuned\n",
    "xgb_base = xgb.XGBRegressor()\n",
    "\n",
    "# Create the random search Random Forest\n",
    "xgb_random = RandomizedSearchCV(estimator = xgb_base, param_distributions = xgb_grid, \n",
    "                                n_iter = 15, cv = 3, verbose = 2, \n",
    "                                random_state = 420, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "# Get the optimal parameters\n",
    "xgb_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final Multiple Linear Regression\n",
    "mlr_final = LinearRegression()\n",
    "\n",
    "# Create the final Random Forest\n",
    "rf_final = RandomForestRegressor(n_estimators = 100,\n",
    "                                 min_samples_split = 6,\n",
    "                                 min_impurity_decrease = 0.0,\n",
    "                                 max_features = 'sqrt',\n",
    "                                 max_depth = 25,\n",
    "                                 criterion = 'mae',\n",
    "                                 bootstrap = True,\n",
    "                                 random_state = 42)\n",
    "\n",
    "# Create the fnal Extreme Gradient Booster\n",
    "xgb_final = xgb.XGBRegressor(tree_method = 'exact',\n",
    "                         objective = 'reg:squarederror',\n",
    "                         n_estimators = 1600,\n",
    "                         min_child_weight = 6,\n",
    "                         max_depth = 8,\n",
    "                         gamma = 0,\n",
    "                         eta = 0.1,\n",
    "                         random_state = 42)\n",
    "\n",
    "# Train the models using 80% of the original data\n",
    "mlr_final.fit(X_train, y_train)\n",
    "rf_final.fit(X_train, y_train)\n",
    "xgb_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that compares all final models\n",
    "def final_comparison(models, test_features, test_labels):\n",
    "    scores = pd.DataFrame()\n",
    "    for model in models:\n",
    "        predictions = model.predict(test_features)\n",
    "        mae = round(mean_absolute_error(test_labels, predictions), 4)\n",
    "        mse = round(mean_squared_error(test_labels, predictions), 4)\n",
    "        r2 = round(r2_score(test_labels, predictions), 4)\n",
    "        errors = abs(predictions - test_labels)\n",
    "        mape = 100 * np.mean(errors / test_labels)\n",
    "        accuracy = round(100 - mape, 4)\n",
    "        scores[str(model)] = [mae, mse, r2, accuracy]\n",
    "    scores.index = ['Mean Absolute Error', 'Mean Squared Error', 'R^2', 'Accuracy']\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the comparison function with the three final models\n",
    "final_scores = final_comparison([mlr_final, rf_final, xgb_final], X_test, y_test)\n",
    "\n",
    "# Adjust the column headers\n",
    "final_scores.columns  = ['Linear Regression', 'Random Forest', 'Extreme Gradient Boosting']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('Portfolio-Tracker': pipenv)",
   "name": "python379jvsc74a57bd00600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}